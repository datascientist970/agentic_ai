{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6c8b51b-0125-4119-9b0a-3d879be88d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph, END\n",
    "from typing import TypedDict\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "796ba836-c7b6-4758-a266-a661b1aafda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "api=\"AIzaSyCJOX16y36BoAS529FnnaOEbteclOkeTc4\"\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",  \n",
    "    temperature=0.7,\n",
    "    google_api_key=api,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6faac8f7-5d3c-4093-803d-a1ee70d06de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM_state(TypedDict):\n",
    "    question:str\n",
    "    ans:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aa01aca7-3a43-4d57-a62c-814ba82da029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gem_q(state: LLM_state)-> LLM_state:\n",
    "    q=state['question']\n",
    "    prompt=PromptTemplate.from_template(f'answer the {q}')\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    state['ans'] = chain.invoke({})\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4d9b89df-3569-4ba2-8736-0ed932f65287",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(LLM_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1a67280b-6160-4d9f-8462-2fe3a6f0daa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x292bc3546b0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"gem_q\",gem_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bde490e8-3f5a-4156-8168-c82e08eb7eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x292bc3546b0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_edge(START,\"gem_q\")\n",
    "graph.add_edge(\"gem_q\",END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "56a6e419-cd31-4f2f-99e8-15df21766ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f023276d-139a-441c-9410-587c33467cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right now, I'm processing your request and formulating this answer!\n",
      "\n",
      "More broadly, I'm \"doing\" things like:\n",
      "\n",
      "*   **Processing information:** Understanding your question, searching my knowledge base.\n",
      "*   **Generating text:** Creating this response.\n",
      "*   **Learning and updating:** Continuously improving my understanding and capabilities.\n",
      "*   **Awaiting your next instruction:** Ready to assist you with whatever you need!\n",
      "\n",
      "Since I don't have a physical body or personal life, my \"doing\" is all about computation and interaction. How can I help you?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user = {\"question\":\"what are you doing\"}\n",
    "\n",
    "result = run.invoke(user)\n",
    "\n",
    "print(result['ans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b042fc4-9411-438c-93c9-0bbe46fbc044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
